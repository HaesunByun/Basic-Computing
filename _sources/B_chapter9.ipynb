{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lT3dK9qsBuC9BAV0JnjF7z53xKGIeCgL","timestamp":1681909525179},{"file_id":"1Sr7tzZ0ELq4GtTcs-hauXuBQdFtH1bi3","timestamp":1656382178299},{"file_id":"1qFNWy96CUa9k4yv5RHUhhZGOL3JLW0lG","timestamp":1656378784544}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WRgazSfAftj6"},"source":["# Chapter 9. 웹과 웹크롤링\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GT3_F344uLCB"},"source":[":::{admonition} 학습목표와 기대효과 \n",":class: info  \n","- 학습목표\n","    - 웹페이지의 구성과 동작을 이해해본다.\n","    - 웹크롤링(web crawling)과 웹스크래핑(web scraping)의 개념을 알아보자.\n","    - urlopen() 함수로 웹크롤링을 해보자.\n","    - BeautifulSoup() 함수로 웹스크랩핑을 해보자.\n","- 기대효과\n","  - 웹페이지가 어떠한 방법으로 만들어지고 동작되는지 이해할 수 있다.\n","  - 웹에서 데이터를 수집할 수 있다.\n",":::"]},{"cell_type":"markdown","source":["## 웹(www)과 HTML\n","웹주소를 보면 보통 시작이 www이다. www는 world wide web의 약자로 web이 거미줄이라는 뜻을 가지고 있어서 전 세계로 퍼진 거미줄로 직역할 수 있다. \n","웹에서 보여지는 페이지(문서)를 웹페이지라고 하며, 웹페이지를 만드는데 사용되는 언어중 하나가 바로 HTML이다.\n"],"metadata":{"id":"z-lQ_zB7EoG6"}},{"cell_type":"markdown","source":["- `HTML`은 Hypertext Markup Language의 약자로, 웹페이지가 어떻게 구조화되어 있는지 웹브라우저(크롬, 익스플로러, 엣지, 사파리 등)가 인식하도록 하는 마크업 언어이다. "],"metadata":{"id":"nxtIy--SIKf0"}},{"cell_type":"markdown","source":[":::{admonition} 마크업(Markup)? 마크다운(Markdown)? \n",":class: tip  \n","- 마크업 언어(Markup Language)란 `태그` 등을 이용하여 문서가 화면에 표시되는 형식을 나타내거나 데이터의 논리적인 구조를 명시하기 위한 규칙들을 정의한 언어의 일종이다. 데이터를 기술한 언어라는 점에서 프로그래밍 언어와는 차이가 있다.\n","\n","- 마크다운 언어(Markdown Language)는 마크업 언어의 일종으로 마크업이 복잡한 태그로 구성되어 있어서 사용하기 힘들어서 만들어진 마크업의 파생형언어이다. 읽기도 쓰기도 쉬운 문서 양식을 지향하므로 복잡한 태그 구조가 사라지고 간단한 텍스트들과 몇 가지 문법만 알면 작성할 수 있다.\n",":::\n"],"metadata":{"id":"b4bimOUoI5ga"}},{"cell_type":"markdown","source":["### 태그(tag)\n","- `HTML로 작성된 페이지는 다양한 태그로 구성`되어 있다. \n","- 태그(tag)는 웹 상의 다른 페이지로 이동하게 하는 하이퍼링크를 생성하거나, 단어를 강조하는 등의 다양한 역할을 한다.\n","- 태그에는 여는(opening) 태그와 닫는(closing) 태그가 있다.\n","- 여는 태그와 닫는 태그 사이에는 내용(content)이 들어간다.\n","```\n","<여는 태그> 내용 </닫는 태그>\n","```\n","- 예를 들어, 아래에서 여는 태그는 `<p>`, 닫는 태그는 `</p>`, 내용은 `아름다운 날이에요.`가 된다.\n","```\n","<p>아름다운 날이에요.</p> \n","```\n","- 여는 태그, 닫는 태그, 내용을 통틀어 요소(element)라고 한다."],"metadata":{"id":"c-AbzSd0NkNP"}},{"cell_type":"markdown","source":["- 아래 매우 간단한 HTML문서를 살펴보자.\n","\n","```\n","<!DOCTYPE html > \n","<html>\n","  <head> \n","    <title> This is my page </title>\n","  </head> \n","  <body>\n","    <p>아름다운 날이에요.</p> \n","  </body>\n","</html >\n","```"],"metadata":{"id":"OWjNZ2WqNNVx"}},{"cell_type":"markdown","source":["- 이 HTML문서를 웹브라우저에서 열면 HTML 코드가 9줄로 구성되었던 것과는 달리 아래와 같이 `아름다운 날이에요.` 한 줄만 보여진다.\n","\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html1.png\" style=\"width:600px;\"></div>"],"metadata":{"id":"2ABeZnIyQgTO"}},{"cell_type":"markdown","source":["- HTML문서안에 들어있는 태그를 하나 하나 파헤쳐보자. \n","- HTML 문서는 `<!DOCTYPE html>` 태그로 시작한다. 이 태그는 문서의 타입을 정의하는 태그로 이 페이지가 html로 구성된 문서임을 웹브라우저가 알게 한다. \n","- 그 이후 여는 태그 `<html>`로 열고, 끝은 닫는 태그 `</html>`로 닫는다. `<html> ~ </html>`는 전체 페이지의 컨텐츠를 포함하는 기본 요소이다.\n","- `<html> ~ </html>` 태그 사이에는 크게 `<head> ~ </head>` 태그와 `<body> ~ </body>`태그로 구성된다. \n","  - `<head> ~ </head>` 태그 안에는 웹페이지의 인코딩 방식, 웹페이지의 제목, CSS(Cascading Stylesheets)의 링크, 그 밖의 부가정보(작성자, 중요 키워드)를 포함한다. 그러나 이러한 정보들은 웹페이지의 제목을 제외하고는 웹 브라우저에 표시되지 않는다.\n","  - `<body>~</body>` 태그 안에는 텍스트, 이미지, 비디오, 게임, 재생 가능한 오디오 트랙 등을 비롯하여 `웹페이지에 표시되는 모든 콘텐츠`가 들어간다."],"metadata":{"id":"AFdeqXxBL7Hs"}},{"cell_type":"markdown","source":["- 태그 안에는 또 다른 태그가 중첩되기도 한다. \n","- 한 예로, 아래에서  `<p> ~ </p>` 태그 사이에 `<strong> ~ </strong>` 태그가 중첩되어 있다. 참고로 `<p>` 태그는 paragraph를 의미하며, `<strong>`은 진하게 나타내라는 의미이다. (웹을 만드는 것이 목적이 아니므로 태그를 외우거나 의미가 무엇인지 알 필요가 없다.)\n","\n","```\n","<p> <strong> 매우 </strong> 반갑습니다.</p>\n","```\n","- 출력 결과는 아래와 같다. \n","<p> <strong> 매우 </strong> 반갑습니다.</p>\n"],"metadata":{"id":"kps1LnRoTtLf"}},{"cell_type":"markdown","source":["- 또한, 일부 태그는 여는 태그만 있고, 닫는 태그가 없는 단일 태그(Single tag) 형태도 있다. \n","- 한 예로, `<img>` 태그는 이미지를 보여주기 위한 태그로 여는 태그만 있다.\n","```\n","<img src=\"https://haesunbyun.github.io/common/images/html2.png\">\n","```\n","- 웹페이지에서 보여지는 결과는 다음과 같다.\n","\n","<img src=\"https://haesunbyun.github.io/common/images/html2.png\">"],"metadata":{"id":"CKO801VjS_4W"}},{"cell_type":"markdown","source":["### 속성(attribute)\n","- 여는 태그안에는 하나 이상의 `속성`을 넣을 수 있다. \n","- 속성은 요소에 추가적인 성질, 링크, 내용 등을 포함시키고 싶을 때 사용하며 실제 웹페이지에 보이지는 않는다.\n","- 속성을 주는 형식은 다음과 같다.\n","```\n","< 여는 태그 속성명=\"속성값\" 속성명=\"속성값\" ...>\n","```\n","- 태그와 속성, 속성과 속성 사이에는 공백이 있으며, 속성 값은 따옴표로 감싸져 있다.\n"],"metadata":{"id":"dOBX-HGRWtgu"}},{"cell_type":"markdown","source":["```\n","<p class=\"editor-note\"> 안녕하세요.</p>\n","<p> 여기는 <a href=\"https://www.snu.ac.kr/\" title=\"서울대학교 홈페이지\">서울대학교</a>입니다.</p>\n","```\n","\n","- img 태그의 `src` p 태그의 `class`, a 태그의 `href`, `title` 이 속성명이다. \n","- `\"https://haesunbyun.github.io/common/images/html2.png\", \"editor-note\", \"https://www.snu.ac.kr/\", \"서울대학교 홈페이지\"`는 속성 값이다.\n","\n","- 웹페이지에서 보여지는 결과는 아래와 같다. 속성이 많지만 웹페이지에서는 보이지 않는다.\n","\n","<p class=\"editor-note\"> 안녕하세요.</p>\n","<p> 여기는 <a href=\"https://www.snu.ac.kr/\" title=\"서울대학교 홈페이지\">서울대학교</a>입니다.</p>"],"metadata":{"id":"2uzBxBR63k-S"}},{"cell_type":"markdown","source":["### 웹 동작\n","- 웹은 다음과 같이 동작한다.\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html3.png\" style=\"width:600px;\"></div>\n","\n","- 일반적으로 웹페이지에 접속하기 위해서는 웹브라우저의 주소입력창에 접속하고자 하는 URL((Uniform Resource Locator)을 입력한다. \n","- URL이 입력되면 브라우저는 HTTP Request 메시지를 웹서버에게 보낸다.\n","- 여기서 HTTP는 HyperText Transfer Protocol의 약자로, 하이퍼미디어 문서를 전송하기 위한 프로토콜이다. 프로토콜이란 컴퓨터들 간 데이터 통신을 원활하게 하기 위해 필요한 통신 규약을 의미한다.\n","- URL 앞에 http:// 또는 https:// 라고 쓰는 이유도 http 프로토콜이 사용된다는 뜻이다.\n","- 웹서버는 HTTP Request 메시지를 받으면 해당 웹문서가 웹서버에 있는지 검색하고 그에 대한 결과를 HTTP Response에 실어 보낸다. 웹문서가 있다면 그 컨텐츠도 함께 넣어 보낸다.\n","- 브라우저에서는 HTTP Response를 받아 웹문서를 브라우저에 나타낸다."],"metadata":{"id":"Ph_TLkNqie_y"}},{"cell_type":"markdown","source":["## 웹크롤링과 웹스크랩핑\n","- 웹은 무한히 많은 데이터가 있는 정보의 바다이다. 이러한 웹에서 유의미한 데이터를 찾는 것은 매우 중요한 일이 됐다.\n","- 웹 페이지에서 정보를 추출하는 프로그램을 웹크롤러(Web Crawler), 또는 스파이더(Spider), 봇(Bot)이라고도 부르며, 크롤러를 사용하여 데이터를 수집하는 것을 크롤링(Crawling)이라고 하다. \n","- 즉, 웹크롤링은 웹페이지의 하이퍼링크를 순회하면서 웹 페이지를 다운로드 하는 작업을 의미한다.\n","- 웹스크랩핑(Scraping)은 다운로드한 웹 페이지에서 필요한 정보를 추출하는 작업을 의미한다.\n","- 일부 모듈들은 웹크롤링과 웹스크랩핑 기능을 모두 갖고 있기도 해서 이를 혼용하여 불리기도 한다."],"metadata":{"id":"OZG13pxncJ-p"}},{"cell_type":"markdown","source":["- 웹크롤링은 다양하게 활용되고 있다.\n","  - 음식점의 예약 상황을 실시간으로 추출하여 어떤 음식점에 자리가 비어있는지, 어떤 요일과 어떤 시간에 어떤 음식점이 인기 있는지 등의 정보를 추출하는데 활용되기도 한다.\n","  - 여러 책 판매 사이트에서 정보를 추출하여 직접 가격 비교해서 최저가 정보를 알려주거나 웹사이트에서 정보를 추출하고 정보를 정리하는데 사용되기도 한다.\n","  - 정부, 자치단체, 기업 등이 자유롭게 사용할 수 있도록 공개한 데이터인 열린 데이터를 수집할 때도 도움이 된다.\n","  - 웹데이터 분석, 자연언어분석, 이미지 처리 등 대량의 데이터 수집이 필요 할 때도 이용된다."],"metadata":{"id":"zQF_NF1cfIsr"}},{"cell_type":"markdown","source":["- 파이썬 언어를 통해 크롤링을 하는 방법은  \n","    - 표준라이브러리인 urllib.request 모듈\n","    - 사람들이 직접 만들어 공개한 라이브러리(서드파티:Third Party)인 requests 모듈, Selenium 모듈 등이 있다.\n","\n","- 스크레이핑(Scraping) 하는 방법은\n","  - re모듈을 사용한 정규표현식으로 추출\n","  - 요소를 지정하는 방식 Xpath와 CSS 선택자\n","  - BeautifulSoup 모듈\n","  - Selenium 모듈 등이 있다.\n"],"metadata":{"id":"iJ2UykKVg_yl"}},{"cell_type":"markdown","source":["### urlopen()으로 웹페이지 가져오기\n","- 웹크롤링을 하기 위해서는 먼저 웹페이지에 접속부터 해야 한다. \n","- 파이썬으로 웹페이지에 접속하기 위해서는 urllib.request 모듈의 urlopen() 함수를 통해 할 수 있다. \n","  - urllib 패키지는 URL과 관련된 작업을 하기 위한 여러 모듈을 모은 패키지로, 그중에서 urllib.request 모듈은 URL을 여는것과 관련한 다양한 함수를 제공하고 있다. \n","- 먼저, urlopen() 함수를 import하고, urlopen() 괄호안에 접속할 사이트의 주소를 넣어준다."],"metadata":{"id":"vuIfi27mqVhb"}},{"cell_type":"markdown","source":["- 아래 웹페이지를 가져와보자. \n","\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html4.png\" style=\"width:400px;\"></div>"],"metadata":{"id":"KbjzYmjNAaX0"}},{"cell_type":"code","source":["from urllib.request import urlopen\n","page = urlopen('https://haesunbyun.github.io/Basic-Computing/mypage2.html')\n","print(page)"],"metadata":{"id":"n5RfbXmBmUFn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 변수 page를 출력해보면, 에러없이 웹페이지를 열었지만 반환된 값은 웹문서 스타일이 아니라 HTTPResponse 객체이다."],"metadata":{"id":"nUJBb8D_pp8a"}},{"cell_type":"markdown","source":["### BeautifulSoup()으로 웹스크랩핑하기\n","- urlopen()으로 가져온 웹페이지를 눈으로 확인 가능한 HTML문서로 바꿔보자.\n","- 이를 위해 BeautifulSoup() 함수를 활용할 수 있다.\n","- BeautifulSoup() 함수는 HTML에서 데이터를 추출할 수 있도록 하는 함수로 HTML 구문 분석 기능을 갖고 있다.\n","    - 참고자료: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n","    "],"metadata":{"id":"TaDBtSOo0E6-"}},{"cell_type":"markdown","source":["- 먼저 bs4모듈에 BeautifulSoup() 함수를 import한다.\n","- BeautifulSoup() 함수의 괄호안에는 첫 번째 전달인자로 구문을 분석하고자 하는 HTML, 두 번째 전달인자로 분석할 파서의 종류를 넣어준다. 여기서는 html 구문으로 파싱할 것이므로 'html.parser'로 적어준다.\n","- 파싱(parsing)이란 구문 분석이라는 뜻으로 각 구성 성분으로 분해하고 이들간의 관계를 분석하여 구조를 결정하는 작업을 말한다.\n","- 파싱하여 변수 soup에 저장하여 출력해보면 urlopen()으로 가져왔던 웹페이지가 html코드로 보여진다.\n","  - 통상적으로 BeautifulSoup()으로 파싱한 객체는 변수 이름을 soup으로 한다."],"metadata":{"id":"VarYquRA5rIS"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","soup=BeautifulSoup(page,'html.parser')\n","print(soup)"],"metadata":{"id":"KcUJKQwNo9Dd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- HTML언어는 파이썬과 다르게 들여쓰기가 필요없는 언어이다.\n","- 그러나 들여쓰기가 되어 있으면 문서의 구조를 파악하는데 도움이 된다. \n","- soup.prettify()는 들여쓰기를 적용해 문서의 구조를 보기 쉽게 바꿔주는 메서드이다."],"metadata":{"id":"Jhlq_51J9Ipe"}},{"cell_type":"code","source":["print(soup.prettify())"],"metadata":{"id":"qT6X3E5r82JJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 웹사이트 https://haesunbyun.github.io/Basic-Computing/mypage3.html 의 페이지를 크롤링해와서 변수 page에 저장하고 page를 HTML코드로 파싱하고 그 결과를 mysoup에 저장한 후 출력하시오."],"metadata":{"id":"i-Ur0U0TBmE0"}},{"cell_type":"code","source":[],"metadata":{"id":"VHXCKoXAL-9J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 태그로 이동\n","- 가져온 웹페이지에서 원하는 데이터를 추출하기 위해서는 데이터에 접근부터 해야한다.\n","- 먼저 데이터가 있는 태그까지 접근하는 방법을 알아보자. \n","- BeautifulSoup은 객체(soup)에 점(.)을 붙여서 태그간 이동을 지원한다. 즉 점을 통해 원하는 태그에 접근할 수 있다.\n","- 변수 soup의 현재 위치는 태그의 가장 바깥쪽인 `<html>` 태그에 위치하고 있고, 구조상 `<html>` 다음 태그로는 `<head>` 태그와 `<body>`가 있다. \n","- 이 가운데 `<body>` 태그로 이동하려면 soup.body와 같이 쓴다.\n","- `<body>` 태그로 이동하면 `<body>` 태그가 가장 바깥쪽 태그로 보여진다."],"metadata":{"id":"ggoWXkxsA5VJ"}},{"cell_type":"code","source":["print(soup.body)"],"metadata":{"id":"mabXZmTrA2df"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 점(.)을 통한 태그 접근은 반드시 순서대로 해야 하는 것은 아니다.\n","- `<body><div><p>`태그가 차례대로 있는데 이 중 `<p>`태그에 접근하려면 soup.p로 쓰면 soup의 현재 위치인 가장 바깥쪽인 <html> 태그에서 아래쪽으로 가장 가까운 `<p>`태그로 이동한다. "],"metadata":{"id":"CBoHL8fMBl8e"}},{"cell_type":"code","source":["soup.p"],"metadata":{"id":"9bdsA5GnBDUS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 그렇다면 다음 `<p>`태그에 접근하려면 어떻게 해야 할까?\n","- 어느 태그의 동일 레벨 즉, 형제 태그에 접근하려면 next_sibling과 previous_sibling을 사용하면 된다.\n","- 같은 부모 태그를 갖는 태그들을 형제(sibling)라고 하는데, 예를 들어, \n","  - `<p class=\"inner-text first-item\" ...>` 태그와, `<p class=\"inner-text second-item\">`는 형제 태그이다.\n","  - 그런데 이 두 태그만 형제인 것이 아니다. 사실 `<p>`태그와 `<p>`태그 사이에는 줄바꿈 기호('\\n')가 들어가 있다. 즉, 줄바꿈 기호도 이들의 형제이다.\n","  - 이 셋의 부모 태그는 `<div>` 태그이다."],"metadata":{"id":"CeHRMV0JDMF4"}},{"cell_type":"code","source":["soup.p.next_sibling"],"metadata":{"id":"3s63gtOBEptc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup.p.next_sibling.next_sibling"],"metadata":{"id":"d65l8EkLHs7c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["soup.a"],"metadata":{"id":"bPzP2WEgC-tt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 아래의 결과가 나오도록 태그로 접근해보세요.\n","\n","```\n","<p>L0444.000400 컴퓨팅 기초: 처음 만나는 컴퓨팅</p>\n","\n","```\n"],"metadata":{"id":"mcMn3tj8iHUC"}},{"cell_type":"code","source":[],"metadata":{"id":"-NT8-gIiDtBj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 아래의 결과가 나오도록 태그로 접근해보세요.\n","\n","```\n","<li class=\"toctree-l1\"><a class=\"reference internal\" href=\"B_chapter1.html\">Chapter 1. 기본자료형과 변수</a></li>\n","\n","```\n"],"metadata":{"id":"EQINko3vDuk0"}},{"cell_type":"code","source":[],"metadata":{"id":"HAUjBdPZEA9l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 텍스트 추출하기\n","- 추출하려는 데이터가 있는 태그까지 접근했다면 텍스트를 추출해보자.\n","- 텍스트를 추출하는 방법은 다음과 같다.\n","  - get_text(): 현재 태그를 포함하여 모든 하위 태그에 있는 텍스트를 추출한다.\n","    - 괄호안에 별도의 옵션을 줄 수 있다. 예) strip=True\n","  - text: 현재 태그를 포함하여 모든 하위 태그에 있는 텍스트를 추출한다.\n","  - .string: 태그에 컨텐츠가 하나인 경우만 추출가능하다.\n","- get_text()와 text는 정확히 동일한 결과를 반환한다. 차이점이 있다면 get_text()의 경우 괄호안에 별도의 옵션을 줄 수 있다는 것이다. 예) get_text(strip=True)\n"],"metadata":{"id":"-8W7zY1-PP49"}},{"cell_type":"code","source":["print(soup.get_text())"],"metadata":{"id":"l0H2ZVXSPcUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(soup.text)"],"metadata":{"id":"9hxMe_T-Vh9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 문자열 앞뒤의 여백(whitespace)를 지울 때에는 strip() 메서드를 사용하면 된다."],"metadata":{"id":"zb1g_Oo9180t"}},{"cell_type":"code","source":["print(soup.text.strip())"],"metadata":{"id":"JcgaOIIsM2DY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- soup.a 태그에는 컨텐츠가 하나이므로 .string으로 문자열 추출이 가능하다."],"metadata":{"id":"USX4a-pXYxu4"}},{"cell_type":"code","source":["print(soup.a.string)"],"metadata":{"id":"KoDn1mhUVtaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- soup에는 하위태그도 많은데다가 각 하위태그마다 컨텐츠가 있어서, 컨텐츠가 여러개 이므로 .string으로 추출할 수 없다."],"metadata":{"id":"3I71jqfXY5YW"}},{"cell_type":"code","source":["soup.string"],"metadata":{"id":"3z3dfljlVqHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 아래의 결과가 나오도록 문자열을 추출해보세요.\n","\n","```\n","Chapter 0. 프로그래밍 언어와 파이썬\n","\n","```\n"],"metadata":{"id":"l6a-t1hbFu71"}},{"cell_type":"code","source":[],"metadata":{"id":"HxjSkHapIgqE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 아래의 결과가 나오도록 문자열을 추출해보세요.\n","\n","```\n","소개#\n","L0444.000400 컴퓨팅 기초: 처음 만나는 컴퓨팅\n","프로그래밍 입문자와 비전공자를 위한 파이썬 프로그래밍 기초와 데이터 과학 기초를 다룬다.\n","컴퓨팅 기초: 처음 만나는 컴퓨팅 001,002,003 강좌 수강생들을 위한 자료이니 복제, 무단배포, 링크공유를 금합니다.\n","\n","Python\n","\n","Chapter 0. 프로그래밍 언어와 파이썬\n","Chapter 1. 기본자료형과 변수\n","Chapter 2. 입출력과 타입변환\n","Chapter 3. 조건문\n","Chapter 4. 반복문\n","Chapter 5. 리스트\n","Chapter 6. 함수\n","Chapter 7. 딕셔너리, 튜플, 셋\n","\n","Web Crawing\n","\n","Chapter 9. 웹과 웹크롤링\n","\n","Data Science\n","```"],"metadata":{"id":"r29TYJlaIXNw"}},{"cell_type":"code","source":[],"metadata":{"id":"Won7F4m-NIDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 태그로 찾기\n","- 위의 예제는 매우 간단한 HTML문서였으므로 태그로 이동하여 데이터까지 접근하는 것이 별로 어려운 일이 아니었다.\n","- 그러나 일반적으로 HTML 문서는 매우 길고, 매우 많은 태그들이 중첩되어 있는 형태를 가진다.\n","- 이와 같을 때는 태그 이동으로 원하는 데이터까지 접근하기에는 사실 매우 번거로운 일이다. \n","- BeautifulSoup은 태그나 속성으로 찾을 수 있도록 find()와 find_all() 메서드를 지원한다.\n","\n","```\n","soup.find('tag명'): 가장 처음에 있는 <tag명> 하나만 반환\n","soup.find_all('tag명'): <tag명>을 모두 찾아내어 리스트와 비슷한 형태로 반환.\n","```"],"metadata":{"id":"FRH0h76EI69Z"}},{"cell_type":"code","source":[],"metadata":{"id":"gWIhMFl9TFDh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 먼저, find() 메서드를 사용해보자.\n","- 아래 코드에서는 tag가 `<p>`인 하나를 찾는데, 가장 먼저 있는 `<p>`태그가 검색된다."],"metadata":{"id":"V_ll2pwxqGOY"}},{"cell_type":"code","source":["soup.find('p')"],"metadata":{"id":"TRVu98vlM07Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 검색된 `<p>`태그에서 문자열을 추출한다."],"metadata":{"id":"fc3qGpUH12xu"}},{"cell_type":"code","source":["soup.find('p').text"],"metadata":{"id":"okT12mZTqejd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 이번에는 find_all() 메서드로 모든 `<p>` 태그를 찾아보자."],"metadata":{"id":"BJvoV-q-q5vb"}},{"cell_type":"code","source":["ptagList = soup.find_all('p')\n","print(ptagList)"],"metadata":{"id":"cz_FKQk4M7hJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- find_all()의 결과는 'bs4.element.ResultSet'이다. 리스트는 아니지만 리스트처럼 보여지며, 리스트와 같이 접근이 가능하다. "],"metadata":{"id":"HxsNpcIJ1qhv"}},{"cell_type":"code","source":["print(type(ptagList))\n","ptagList[0]"],"metadata":{"id":"D79an7k9qEJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","- 또한 문자열 추출도 가능하다."],"metadata":{"id":"nUDxiNtn1ti2"}},{"cell_type":"code","source":["ptagList[0].text"],"metadata":{"id":"VPfOFh7wrglF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 'bs4.element.ResultSet'은 반복가능한 데이터셋이다. \n","- 즉, 리스트처럼 반복문에서 활용할 수 있다."],"metadata":{"id":"vZo83kPar7mo"}},{"cell_type":"code","source":["for each in soup.find_all('p'):\n","  print(each.text)"],"metadata":{"id":"Nw-4rOw1p92B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for each in soup.find_all('a'):\n","  print(each.string)"],"metadata":{"id":"x3be5ohRIpCM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 아래의 내용을 출력해보세요.\n","\n","\n","```\n","Chapter 0. 프로그래밍 언어와 파이썬\n","Chapter 1. 기본자료형과 변수\n","Chapter 2. 입출력과 타입변환\n","Chapter 3. 조건문\n","Chapter 4. 반복문\n","Chapter 5. 리스트\n","Chapter 6. 함수\n","Chapter 7. 딕셔너리, 튜플, 셋\n","Chapter 9. 웹과 웹크롤링\n","```\n"],"metadata":{"id":"EJGqJkmSpgdT"}},{"cell_type":"code","source":[],"metadata":{"id":"WjmsUgCKNfN0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 속성으로 찾기\n","- find()나 find_all()함수에서 전달인자로 태그 안에 있는 속성명이나 속성값을 함께 지정하여 찾을 수도 있다.\n","- 조건을 여러개 지정하면 찾고자 하는 데이터에 더 근접하여 추출할 수 있다. \n","- 조건을 속성명만 줄 때에는 태그명을 생략할 수도 있다.\n","```\n","soup.find('tag명', 속성명='속성값')\n","soup.find_all(속성명='속성값')\n","```"],"metadata":{"id":"8MxGSWAy1Fei"}},{"cell_type":"markdown","source":["- 예를들어, 태그가 `<p>`이면서 class가 'outer-text'인 것을 모두 찾는다면 아래와 같이 쓸 수 있다.\n","- 이때 주의해야 할 것은 class라는 속성명은 반드시 class_로 써야 한다. "],"metadata":{"id":"c8kVf0AqzmnU"}},{"cell_type":"code","source":["soup.find_all('p', class_='outer-text')"],"metadata":{"id":"MB_mJjbO1LoQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 속성명 id가 'first'인 것을 모두 찾아서 내용만 출력한다."],"metadata":{"id":"sUQTnGrk2dDi"}},{"cell_type":"code","source":["for each in soup.find_all(id='first'):\n","  print(each.text)"],"metadata":{"id":"Op6GqQxf2cmn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 속성명이 class이면서 속성값이 caption인 것을 모두 찾아 출력하시오.\n","\n","```\n","Python\n","Web Crawing\n","Data Science\n","```\n"],"metadata":{"id":"7VRGcL3-J7Nx"}},{"cell_type":"code","source":[],"metadata":{"id":"JC92w2GUN54l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 속성값 추출하기\n","- 어떤 경우에는 속성값을 추출해야 할 필요가 있기도 하다.  대표적인 예로 링크주소를 추출하고 싶을 때가 그렇다.\n","- 이럴 때에는 속성명을 활용하여 속성값을 추출하면 된다.\n","- 속성값을 추출할 때에는 태그 뒤 대괄호[ ] 안에  속성명을 문자열로 넣어주면 된다. \n","```\n","soup.find('p')['속성명']\n","```"],"metadata":{"id":"xUhcaTXP1JGX"}},{"cell_type":"markdown","source":["- 태그로 직접 접근해 속성값을 추출할 수 있다."],"metadata":{"id":"7ZatiW9sOA4y"}},{"cell_type":"code","source":["soup.p['class']"],"metadata":{"id":"gx4alct87S9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- find() 메서드로 찾아 속성값을 추출할 수 있다."],"metadata":{"id":"jK3UP0w32Sdg"}},{"cell_type":"code","source":["soup.find('p')['class']"],"metadata":{"id":"bPgoe0lF5fhc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- find_all() 메서드로 찾아 속성값을 추출할 수 있다."],"metadata":{"id":"7ElyA2MI2UpC"}},{"cell_type":"code","source":["for each in soup.find_all('p'):\n","  print(each['class'])"],"metadata":{"id":"wTW2gF9T7aNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for each in soup.find_all('a'):\n","  print(f\"{each['href']} : {each.string}\")"],"metadata":{"id":"X-KX9F-NOeg_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 mysoup에서 속성명이 href인 속성값을 모두 찾아 다음과 같은 형태로 출력하시오.\n","\n","```\n","B_chapter0.html ----> Chapter 0. 프로그래밍 언어와 파이썬\n","B_chapter1.html ----> Chapter 1. 기본자료형과 변수\n","B_chapter2.html ----> Chapter 2. 입출력과 타입변환\n","B_chapter3.html ----> Chapter 3. 조건문\n","B_chapter4.html ----> Chapter 4. 반복문\n","B_chapter5.html ----> Chapter 5. 리스트\n","B_chapter6.html ----> Chapter 6. 함수\n","B_chapter7.html ----> Chapter 7. 딕셔너리, 튜플, 셋\n","B_chapter9.html ----> Chapter 9. 웹과 웹크롤링\n","```\n"],"metadata":{"id":"ONDbAsjd0dSh"}},{"cell_type":"markdown","source":["### 개발자 도구 활용하기\n","- 앞에서 말했던 바와 같이 HTML 문서는 매우 길고 많은 태그들이 중첩되어 있어서 구조를 파악하기가 쉽지 않다.\n","- 이를 위해 웹페이지의 구조를 파악하기 쉽도록 구조를 보여주는 도구가 바로 `개발자 도구`이다. \n","- 개발자 도구는 브라우저에서 일반적으로 `오른쪽 상단에 (...)를 클릭하여 도구 더보기 > 개발자 도구`를 클릭하면 보인다.\n","- 단축키는 F12 또는 Ctrl+Shift+I이다.\n","- 개발자 도구를 활용하여 태그를 찾아보는 연습을 해보자."],"metadata":{"id":"nllLFTUIUl10"}},{"cell_type":"markdown","source":["#### 1단계: urlopen()으로 웹페이지를 가져오기\n","- 예를 들어, 네이버 증권의 시장지표 사이트를 크롤링해보자.\n","- 웹에서 추출하고자 데이터는 네이버 증권사이트에서 환전 고시 환율, 국제 시장 환율, 유가.금시세라고 가정해보자.\n","\n","- 먼저, 크롬 브라우저를 활용해 네이버에 접속해서 증권 메뉴에서 시장지표를 클릭하여 해당사이트까지 이동한다.\n","- 브라우저의 주소 입력창에 나오는 링크를 복사한다.\n","- 아래 코드의 urlopen()함수의 괄호안에 붙여넣는다."],"metadata":{"id":"q4I8Odb5ZzE5"}},{"cell_type":"code","source":["from urllib.request import urlopen\n","page = urlopen('https://finance.naver.com/marketindex/')\n","print(page)"],"metadata":{"id":"-KRcSGEkP5eD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682644341727,"user_tz":-540,"elapsed":859,"user":{"displayName":"­변해선 / 강의교수 / 기초교육원","userId":"11375408609059084889"}},"outputId":"6da89540-52a8-45dc-e1d8-861865dbb492"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<http.client.HTTPResponse object at 0x7f70a5929390>\n"]}]},{"cell_type":"markdown","source":["#### 2단계: BeautifulSoup()으로 파싱하기\n","- BeautifulSoup()을 활용해 HTML 파싱을 해서 soup객체로 만든다.\n","- 여기까지는 앞에서 했던 것과 동일하다."],"metadata":{"id":"OB8j0tGyaybR"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","soup=BeautifulSoup(page,'html.parser')\n","#print(soup)"],"metadata":{"id":"xuGFzbN_bxJV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3단계: 개발자 도구 활용\n","-  개발자 도구를 활용하여 추출하고자 하는 데이터가 어느 태그에 혹은 어떤 속성을 갖고 있는지 확인한다.\n","- 이를 위해 개발자 도구 F12 또는 ... > 도구 더보기 > 개발자 도구를 클릭한다.\n","\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html5.png\" style=\"width:600px;\"></div>"],"metadata":{"id":"TKjyj9rBcKUb"}},{"cell_type":"markdown","source":["- 요소(element) 선택 버튼을 클릭한다.\n","- `요소 선택 버튼`은 현재 로딩된 웹페이지의 컨텐츠로 마우스를 가져가면 해당 요소의 상세 정보(태그 정보, CSS 정보)와 소스보기의 해당 요소 위치로 바로 이동시켜주는 기능을 제공한다.\n","- 마우스를 이동시킬 때마다 소스보기에서도 음영처리된 부분이 바뀌는 것을 볼 수 있을 것이다.\n","\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html6.png\" style=\"width:600px;\"></div>"],"metadata":{"id":"hdTzdWN5hfUX"}},{"cell_type":"markdown","source":["- 환전 고시 환율, 국제 시장 환율, 유가.금시세 정보를 추출하기 위해 미국USD 컨텐츠로 마우스를 가져가보자. \n","- 도움말 기능으로 태그의 상세 정보인 h3.h_lst가 보인다. \n","- 좀 더 자세히 확인해보기 위해 클릭한 후, 소스보기의 음영처리 된 부분으로 가보자.\n","- 미국USD라는 텍스트는 `<h3 class=\"h_lst\">`에 들어있다.\n","- 태그 옆에는 작은 삼각형이 보이는데, 이 삼각형을 클릭하여 소스보기를 접거나 펼칠 수 있다.\n","- 삼각형을 눌러 펼쳐보면 `<span class=\"blind\">미국 USD</span>`태그에 미국 USD 컨텐츠가 들어있다. \n","\n","\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html7.png\" style=\"width:600px;\"></div>"],"metadata":{"id":"zv8qm_QAkg3C"}},{"cell_type":"markdown","source":["- 추출하고자 하는 데이터를 몇 개 더 동일한 방법으로 확인해보자.\n","- 일본JPY나 유로/달러 등의 컨텐츠도 동일한 태그인 것을 확인했다면 이제 그 태그를 이용하여 데이터를 추출할 수 있다.\n","- 이때 태그를 잘 선택하는 것이 매우 중요하다. 우리는 두 가지의 옵션을 가지고 있다.\n","  - 첫 번째 옵션은 ```<h3 class=\"h_lst\">```로 태그가 h3이고 class가 h_lst인 컨텐츠를 찾는 것\n","  - 두 번째 옵션은 ```<span class=\"blind\">```로 태그가 span이고 class가 blind로 찾는 것\n","- 어떤 태그로 찾는 것이 가장 최소한의 노력으로 헛일하지 않고 원하는 데이터를 추출할 수 있는지 생각해야 한다.\n","\n"],"metadata":{"id":"skE35lz5op_e"}},{"cell_type":"markdown","source":["#### 4단계: find_all()로 찾기\n","- 두 가지 옵션 모두 테스트해보자.\n","- 먼저 ```soup.find_all('h3', class_=\"h_lst\")```는 추출하려고 했던 데이터가 태그 안에 예쁘게 들어가 있다.\n"],"metadata":{"id":"4topM-CFqfhq"}},{"cell_type":"code","source":["soup.find_all('h3', class_=\"h_lst\")"],"metadata":{"id":"HQhyGHiqqZV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 두 번째 옵션은 ```soup.find_all('span', class_=\"blind\")```는 추출하려고 했던 데이터뿐만 아니라 원, 하락, 상승과 같은 필요하지 않은 데이터까지 포함되어 있다.\n","- 어떤 태그를 활용해야 데이터를 잘 추출할 것인가는 여러 번의 연습과 시행착오를 거쳐서 감을 잡는 것이 필요하다.^^;; "],"metadata":{"id":"d9kIPdZtrjks"}},{"cell_type":"code","source":["soup.find_all('span', class_=\"blind\")"],"metadata":{"id":"YSpvqM4pq6OB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 그럼 find_all()로 찾은 요소들을 변수에 저장해보자.\n","- 앞에서도 설명한 바와 같이, find_all()의 결과는 'bs4.element.ResultSet'이다. 리스트는 아니지만 리스트처럼 보여지며, 리스트와 같이 접근이 가능하다고 얘기했었다.\n","- 인덱스접근과 반복문에 활용 할 수 있다는 것이다. "],"metadata":{"id":"THmYDB5n1VKc"}},{"cell_type":"code","source":["fList = soup.find_all('h3', class_=\"h_lst\")\n","print(fList[0])\n","print(fList[0].string)"],"metadata":{"id":"py65hldb1Q_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for each in fList:\n","  print(each.string)"],"metadata":{"id":"cGUOnt4g3SfC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["😄 환전 고시 환율, 국제 시장 환율, 유가.금시세의 가격을 추출하여 아래와 같이 출력하시오.\n","\n","```\n","1,339.50\n","1,339.50\n","999.51\n","1,478.00\n","193.25\n","134.1100\n","1.1011\n","1.2466\n","101.2500\n","74.76\n","1664.17\n","1999.0\n","85538.28\n","```\n"],"metadata":{"id":"ZG6a6Buq3Qqi"}},{"cell_type":"markdown","source":["😄 환전 고시 환율, 국제 시장 환율, 유가.금시세 최종 데이터를 아래와 같이 출력하시오.\n","\n","```\n","미국 USD : 1,339.50\n","일본 JPY(100엔) : 999.51\n","유럽연합 EUR : 1,478.00\n","중국 CNY : 193.25\n","달러/일본 엔 : 134.1100\n","유로/달러 : 1.1011\n","영국 파운드/달러 : 1.2466\n","달러인덱스 : 101.2500\n","WTI : 74.76\n","휘발유 : 1664.17\n","국제 금 : 1999.0\n","국내 금 : 85538.28\n","```\n"],"metadata":{"id":"W8G7TNwC61nc"}},{"cell_type":"markdown","source":["## 마무리\n","- 웹페이지를 만드는데 사용되는 언어중 하나가 바로 HTML이다.\n","- HTML은 태그와 내용으로 구성되어 있다.\n","- 웹페이지 크롤링은 urllib.request 모듈의 urlopen() 함수를 통해 할 수 있다\n","- BeautifulSoup() 함수는 HTML에서 데이터를 추출할 수 있도록 하는 함수로 HTML 구문 분석 기능을 갖고 있다.\n","- html에서 태그 찾기는 \n","  - soup.find('tag명'): 첫 <tag명>을 찾아 반환\n","  - soup.find_all('tag명'): <tag명>을 모두 찾아 묶음으로 반환\n","  - 속성명 = ＇속성값'을 괄호안에 추가로 넣어서 찾을 수 있다.\n","- 태그에서 데이터 추출하기는\n","  - 속성값 추출하기: ['속성명'] 활용\n","  - tag의 Text 추출하기: get_text(), text, string 등으로 추출할 수 있다.\n","- 웹페이지의 구조를 파악하기 쉽도록 구조를 보여주는 도구가 바로 개발자 도구이다.\n","- 개발자 도구를 활용하여 추출하고자 하는 데이터의 태그명과 속성을 확인할 수 있다.\n"],"metadata":{"id":"qd79ookGJz8i"}}]}