{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1lT3dK9qsBuC9BAV0JnjF7z53xKGIeCgL","timestamp":1681909525179},{"file_id":"1Sr7tzZ0ELq4GtTcs-hauXuBQdFtH1bi3","timestamp":1656382178299},{"file_id":"1qFNWy96CUa9k4yv5RHUhhZGOL3JLW0lG","timestamp":1656378784544}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WRgazSfAftj6"},"source":["# Chapter 9. 웹과 웹크롤링\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GT3_F344uLCB"},"source":[":::{admonition} 학습목표와 기대효과\n",":class: info  \n","- 학습목표\n","    - 웹페이지의 구성과 동작을 이해한다.\n","    - 웹크롤링(web crawling)과 웹스크래핑(web scraping)의 개념을 알아보자.\n","    - urlopen() 함수로 웹크롤링을 해보자.\n","    - BeautifulSoup() 함수로 웹스크랩핑을 해보자.\n","- 기대효과\n","  - 웹페이지가 어떠한 방법으로 만들어지고 동작되는지 이해할 수 있다.\n","  - 웹에서 데이터를 수집할 수 있다.\n",":::"]},{"cell_type":"markdown","source":["## 웹(www)과 HTML\n","웹주소를 보면 보통 시작이 www이다. www는 world wide web의 약자로 web이 거미줄이라는 뜻을 가지고 있어서 전 세계로 퍼진 거미줄로 직역할 수 있다.\n","웹에서 보여지는 페이지(문서)를 웹페이지라고 하며, 웹페이지를 만드는데 사용되는 언어중 하나가 바로 HTML(HyperText Markup Language)이다.\n"],"metadata":{"id":"z-lQ_zB7EoG6"}},{"cell_type":"markdown","source":["### 태그(tag)\n","- `HTML로 작성된 페이지는 다양한 태그로 구성`되어 있다.\n","- 태그에는 여는(opening) 태그와 닫는(closing) 태그가 있다.\n","- 태그(tag) 사이에는 내용(content)이 들어가며, 웹 상의 다른 페이지로 이동하게 하는 하이퍼링크를 생성하거나, 단어를 강조하는 등의 다양한 역할을 한다.\n","\n","```\n","<여는 태그> 내용 </닫는 태그>\n","```\n","- 예를 들어, 아래에서 여는 태그는 `<p>`, 닫는 태그는 `</p>`, 내용은 `아름다운 날이에요.`가 된다.\n","```\n","<p>아름다운 날이에요.</p>\n","```\n","- 여는 태그, 닫는 태그, 내용을 통틀어 요소(element)라고 한다."],"metadata":{"id":"c-AbzSd0NkNP"}},{"cell_type":"markdown","source":["- 아래 매우 간단한 HTML문서를 살펴보자.\n","\n","```\n","<!DOCTYPE html >\n","<html>\n","  <head>\n","    <title> This is my page </title>\n","  </head>\n","  <body>\n","    <p>아름다운 날이에요.</p>\n","  </body>\n","</html >\n","```"],"metadata":{"id":"OWjNZ2WqNNVx"}},{"cell_type":"markdown","source":["- 이 HTML문서를 웹브라우저에서 열면 HTML 코드가 9줄로 구성되었던 것과는 달리 아래와 같이 `아름다운 날이에요.` 한 줄만 보여진다.\n","\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html1.png\" style=\"width:600px;\"></div>"],"metadata":{"id":"2ABeZnIyQgTO"}},{"cell_type":"markdown","source":["- HTML문서안에 들어있는 태그를 살펴보자.\n","- HTML 문서는 `<!DOCTYPE html>` 태그로 시작한다. 이 태그는 문서의 타입을 정의하는 태그로 이 페이지가 html로 구성된 문서임을 웹브라우저가 알게 한다.\n","- 그 이후 여는 태그 `<html>`로 열고, 끝은 닫는 태그 `</html>`로 닫는다. `<html> ~ </html>`는 전체 페이지의 컨텐츠를 포함하는 기본 요소이다.\n","- `<html> ~ </html>` 태그 사이에는 크게 `<head> ~ </head>` 태그와 `<body> ~ </body>`태그로 구성된다.\n","  - `<head> ~ </head>` 태그 안에는 웹페이지의 인코딩 방식, 웹페이지의 제목, CSS(Cascading Stylesheets)의 링크, 그 밖의 부가정보(작성자, 중요 키워드)를 포함한다. 그러나 이러한 정보들은 웹페이지의 제목을 제외하고는 웹 브라우저에 표시되지 않는다.\n","  - `<body>~</body>` 태그 안에는 텍스트, 이미지, 비디오, 게임, 재생 가능한 오디오 트랙 등을 비롯하여 `웹페이지에 표시되는 모든 콘텐츠`가 들어간다."],"metadata":{"id":"AFdeqXxBL7Hs"}},{"cell_type":"markdown","source":["- 태그 안에는 또 다른 태그가 중첩되기도 한다.\n","- 한 예로, 아래에서  `<p> ~ </p>` 태그 사이에 `<strong> ~ </strong>` 태그가 중첩되어 있다. 참고로 `<p>` 태그는 paragraph를 의미하며, `<strong>`은 진하게 나타내라는 의미이다. (웹을 만드는 것이 목적이 아니므로 태그를 외우거나 의미가 무엇인지 알지 못해도 좋다.)\n","\n","```\n","<p> 수강취소 안하고 여기까지 온 <strong> 당신 매우 멋지십니다.</strong> </p>\n","```\n","- 출력 결과는 아래와 같다.\n","<p> 수강취소 안하고 여기까지 온 <strong> 당신 매우 멋지십니다.</strong> </p>\n"],"metadata":{"id":"kps1LnRoTtLf"}},{"cell_type":"markdown","source":["- 또한, 일부 태그는 여는 태그만 있고, 닫는 태그가 없는 단일 태그(Single tag) 형태도 있다.\n","- 한 예로, `<img>` 태그는 이미지를 보여주기 위한 태그로 여는 태그만 있다.\n","```\n","<img src=\"https://haesunbyun.github.io/common/images/html2.png\">\n","```\n","- 웹페이지에서 보여지는 결과는 다음과 같다.\n","\n","<img src=\"https://haesunbyun.github.io/common/images/html2.png\">"],"metadata":{"id":"CKO801VjS_4W"}},{"cell_type":"markdown","source":["### 속성(attribute)\n","- 여는 태그안에는 하나 이상의 `속성`을 넣을 수 있다.\n","- 속성은 요소에 추가적인 성질, 링크, 내용 등을 포함시키고 싶을 때 사용하며 실제 웹페이지에 보이지는 않는다.\n","- 속성을 주는 형식은 다음과 같다.\n","```\n","< 여는 태그 속성명=\"속성값\" 속성명=\"속성값\" ...>\n","```\n","- 태그와 속성, 속성과 속성 사이에는 공백이 있으며, 속성 값은 따옴표로 감싸져 있다.\n"],"metadata":{"id":"dOBX-HGRWtgu"}},{"cell_type":"markdown","source":["```\n","<p class=\"editor-note\"> 안녕하세요.</p>\n","<p> 여기는 <a href=\"https://www.snu.ac.kr/\" title=\"서울대학교 홈페이지\">서울대학교</a>입니다.</p>\n","<img src=\"https://haesunbyun.github.io/common/images/html2.png\">\n","```\n","\n","- p 태그의 `class`, a 태그의 `href`와 `title`, img 태그의 `src`가 속성명이다.\n","- `\"editor-note\", \"https://www.snu.ac.kr/\", \"서울대학교 홈페이지\"`, \"https://haesunbyun.github.io/common/images/html2.png\" 는 속성 값이다.\n","\n","- 웹페이지에서 보여지는 결과는 아래와 같다. 속성이 많지만 웹페이지에서는 보이지 않는다.\n","---\n","<p class=\"editor-note\"> 안녕하세요.</p>\n","<p> 여기는 <a href=\"https://www.snu.ac.kr/\" title=\"서울대학교 홈페이지\">서울대학교</a>입니다.</p>\n","<img src=\"https://haesunbyun.github.io/common/images/html2.png\">"],"metadata":{"id":"2uzBxBR63k-S"}},{"cell_type":"markdown","source":["### 웹 동작\n","- 웹은 다음과 같이 동작한다.\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/html3.png\" style=\"width:600px;\"></div>\n","\n","- <font size=5>①</font> 일반적으로 웹페이지에 접속하기 위해서는 웹브라우저의\n","주소입력창에 접속하고자 하는 URL((Uniform Resource Locator)을 입력한다.\n","- <font size=5>②</font> URL이 입력되면 브라우저는 HTTP Request 메시지를 웹서버에게 보낸다.\n","- 여기서 HTTP는 HyperText Transfer Protocol의 약자로, 하이퍼미디어 문서를 전송하기 위한 프로토콜이다. 프로토콜이란 컴퓨터들 간 데이터 통신을 원활하게 하기 위해 필요한 통신 규약을 의미한다.\n","- URL 앞에 http:// 또는 https:// 라고 쓰는 이유도 http 프로토콜이 사용된다는 뜻이다.\n","- <font size=5>③</font> 웹서버는 HTTP Request 메시지를 받으면 해당 웹문서가 웹서버에 있는지 검색한다.\n","- <font size=5>④</font> 검색 결과를 HTTP Response에 실어 보낸다. 검색된 웹문서가 있다면 그 컨텐츠도 함께 넣어 보낸다.\n","- <font size=5>⑤</font> 브라우저에서는 HTTP Response를 받아 웹문서를 브라우저에 나타낸다."],"metadata":{"id":"Ph_TLkNqie_y"}},{"cell_type":"markdown","source":["## 웹크롤링과 웹스크랩핑\n","- 웹은 무한히 많은 데이터가 있는 정보의 바다이다. 이러한 웹에서 유의미한 데이터를 찾는 것은 매우 중요한 일이 됐다.\n","- 웹 페이지에서 정보를 추출하는 프로그램을 웹크롤러(Web Crawler), 또는 스파이더(Spider), 봇(Bot)이라고도 부르며, 크롤러를 사용하여 데이터를 수집하는 것을 크롤링(Crawling)이라고 하다.\n","- 즉, 웹크롤링은 웹페이지의 하이퍼링크를 순회하면서 웹 페이지를 다운로드 하는 작업을 의미한다.\n","- 웹스크랩핑(Scraping)은 다운로드한 웹 페이지에서 필요한 정보를 추출하는 작업을 의미한다.\n","- 일부 모듈들은 웹크롤링과 웹스크랩핑 기능을 모두 갖고 있기도 해서 이를 혼용하여 부르기도 한다."],"metadata":{"id":"OZG13pxncJ-p"}},{"cell_type":"markdown","source":["- 웹크롤링은 다양하게 활용되고 있다.\n","  - 음식점의 예약 상황을 실시간으로 추출하여 어떤 음식점에 자리가 비어있는지, 어떤 요일과 어떤 시간에 어떤 음식점이 인기 있는지 등의 정보를 추출하는데 활용되기도 한다.\n","  - 여러 책 판매 사이트에서 정보를 추출하여 직접 가격 비교해서 최저가 정보를 알려주거나 웹사이트에서 정보를 추출하고 정보를 정리하는데 사용되기도 한다.\n","  - 정부, 자치단체, 기업 등이 자유롭게 사용할 수 있도록 공개한 데이터인 열린 데이터를 수집할 때도 도움이 된다.\n","  - 웹데이터 분석, 자연언어분석, 이미지 처리 등 대량의 데이터 수집이 필요 할 때도 이용된다."],"metadata":{"id":"zQF_NF1cfIsr"}},{"cell_type":"markdown","source":["### urllib.request 모듈의 urlopen()으로 웹페이지 크롤링하기\n","- 웹크롤링을 하기 위해서는 먼저 웹페이지에 접속부터 해야 한다.\n","- 파이썬으로 웹페이지에 접속하기 위해서는 urllib.request 모듈의 urlopen() 함수를 통해 할 수 있다.\n","  - urllib 패키지는 URL과 관련된 작업을 하기 위한 여러 모듈을 모은 패키지로, 그중에서 urllib.request 모듈은 URL을 여는것과 관련한 다양한 함수를 제공하고 있다.\n","- 먼저, urlopen() 함수를 import하고, urlopen() 괄호안에 접속할 사이트의 주소를 넣어준다."],"metadata":{"id":"vuIfi27mqVhb"}},{"cell_type":"markdown","source":["- 아래 웹페이지를 가져와보자."],"metadata":{"id":"KbjzYmjNAaX0"}},{"cell_type":"code","source":["from urllib.request import urlopen\n","page = urlopen('https://haesunbyun.github.io/Basic-Computing/mypage3.html')\n","print(page)"],"metadata":{"id":"n5RfbXmBmUFn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 변수 page를 출력해보면, 에러없이 웹페이지를 열었지만 반환된 값은 웹문서 스타일이 아니라 HTTPResponse 객체이다."],"metadata":{"id":"nUJBb8D_pp8a"}},{"cell_type":"markdown","source":["### BeautifulSoup()으로 웹스크랩핑하기\n","- urlopen()으로 가져온 웹페이지를 눈으로 확인 가능한 HTML문서로 바꿔보자.\n","- 이를 위해 BeautifulSoup() 함수를 활용할 수 있다.\n","- BeautifulSoup() 함수는 HTML에서 데이터를 추출할 수 있도록 하는 함수로 HTML 구문 분석 기능을 갖고 있다.\n","    - 참고자료: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n","    "],"metadata":{"id":"TaDBtSOo0E6-"}},{"cell_type":"markdown","source":["- 먼저 bs4모듈에 BeautifulSoup() 함수를 import한다.\n","- BeautifulSoup() 함수의 괄호안에는 첫 번째 전달인자로 구문을 분석하고자 하는 HTML, 두 번째 전달인자로 분석할 파서의 종류를 넣어준다. 여기서는 html 구문으로 파싱할 것이므로 'html.parser'로 적어준다.\n","- 파싱(parsing)이란 구문 분석이라는 뜻으로 각 구성 성분으로 분해하고 이들간의 관계를 분석하여 구조를 결정하는 작업을 말한다.\n","- 파싱하여 변수 soup에 저장하여 출력해보면 urlopen()으로 가져왔던 웹페이지가 html코드로 보여진다.\n","  - 통상적으로 BeautifulSoup()으로 파싱한 객체는 변수 이름을 soup으로 한다."],"metadata":{"id":"VarYquRA5rIS"}},{"cell_type":"code","source":["from bs4 import BeautifulSoup\n","soup=BeautifulSoup(page,'html.parser')\n","print(soup)"],"metadata":{"id":"KcUJKQwNo9Dd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- HTML언어는 파이썬과 다르게 들여쓰기가 필요없는 언어이다.\n","- 그러나 들여쓰기가 되어 있으면 문서의 구조를 파악하는데 도움이 된다.\n","- soup.prettify()는 들여쓰기를 적용해 문서의 구조를 보기 쉽게 바꿔주는 메서드이다."],"metadata":{"id":"Jhlq_51J9Ipe"}},{"cell_type":"code","source":["print(soup.prettify())"],"metadata":{"id":"qT6X3E5r82JJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 태그 이동\n","- 가져온 웹페이지에서 원하는 데이터를 추출하기 위해서는 데이터에 접근부터 해야한다.\n","- 먼저 데이터가 있는 태그까지 접근하는 방법을 알아보자.\n","- BeautifulSoup은 객체(soup)에 점(.)을 붙여서 태그간 이동을 지원한다. 즉 점을 통해 원하는 태그에 접근할 수 있다.\n","- <font color=\"red\">변수 soup의 현재 위치는 태그의 가장 바깥쪽인 `<html>` 태그에 위치</font>하고 있고, 구조상 `<html>` 다음 태그로는 `<head>` 태그와 `<body>`가 있다.\n","- 이 가운데 `<body>` 태그로 이동하려면 soup.body와 같이 쓴다.\n","- `<body>` 태그로 이동하면 `<body>` 태그가 가장 바깥쪽 태그로 보여진다."],"metadata":{"id":"ggoWXkxsA5VJ"}},{"cell_type":"code","source":["print(soup.body)"],"metadata":{"id":"mabXZmTrA2df"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 점(.)을 통한 태그 접근은 반드시 태그 순서대로 해야 하는 것은 아니다.\n","- `<body><div><p>`태그가 차례대로 있는데 이 중 `<p>`태그에 접근하려면 soup.p로 쓰면 soup의 현재 위치인 가장 바깥쪽인 <html> 태그에서 아래쪽으로 가장 가까운 `<p>`태그로 이동한다."],"metadata":{"id":"CBoHL8fMBl8e"}},{"cell_type":"code","source":["soup.p"],"metadata":{"id":"9bdsA5GnBDUS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 텍스트 추출하기\n","- 추출하려는 데이터가 있는 태그까지 접근했다면 텍스트를 추출해보자.\n","- 텍스트를 추출하는 방법은 다음과 같다.\n","  - get_text(): 현재 태그를 포함하여 모든 하위 태그에 있는 텍스트를 추출한다.\n","    - 괄호안에 별도의 옵션을 줄 수 있다. 예) strip=True\n","  - text: 현재 태그를 포함하여 모든 하위 태그에 있는 텍스트를 추출한다.\n","  - .string: 태그에 컨텐츠가 하나인 경우만 추출가능하다.\n","- get_text()와 text는 정확히 동일한 결과를 반환한다. 차이점이 있다면 get_text()의 경우 괄호안에 별도의 옵션을 줄 수 있다는 것이다. 예) get_text(strip=True)\n"],"metadata":{"id":"-8W7zY1-PP49"}},{"cell_type":"code","source":["print(soup.get_text())"],"metadata":{"id":"l0H2ZVXSPcUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(soup.text)"],"metadata":{"id":"9hxMe_T-Vh9c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 문자열 앞뒤의 여백(whitespace)를 지울 때에는 strip() 메서드를 사용하면 된다. 여기서 문자열의 기준은 soup위치 기준이다."],"metadata":{"id":"zb1g_Oo9180t"}},{"cell_type":"code","source":["print(soup.text.strip())"],"metadata":{"id":"JcgaOIIsM2DY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- soup.a 태그에는 컨텐츠가 하나이므로 .string으로 문자열 추출이 가능하다."],"metadata":{"id":"USX4a-pXYxu4"}},{"cell_type":"code","source":["print(soup.a.string)"],"metadata":{"id":"KoDn1mhUVtaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 그러나 .string 추출하려는 태그 안에 컨텐츠가 여러 개이면 추출할 수 없다.\n","- 예를 들어, soup에는 하위태그도 많은데다가 각 하위태그마다 컨텐츠가 있어서, 즉 컨텐츠가 여러개 이므로 .string으로는 추출할 수 없다."],"metadata":{"id":"3I71jqfXY5YW"}},{"cell_type":"code","source":["soup.string"],"metadata":{"id":"3z3dfljlVqHA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 개발자 도구 활용하기\n","- HTML 문서는 매우 길고 많은 태그들이 중첩되어 있어서 구조를 파악하기가 쉽지 않다. 구조 파악이 어렵기 때문에 점(.)을 통한 이동으로 데이터를 추출하기가 매우 어렵다.(그렇다고 점(.)을 통한 이동이 사용되지 않는 것은 아니다.)\n","- 이를 위해 웹페이지의 구조를 파악하기 쉽도록 구조를 보여주는 도구가 바로 `개발자 도구`이다.\n","- 개발자 도구를 활용하면 추출하고자 하는 데이터가 어느 태그에 혹은 어떤 속성을 갖고 있는지 쉽게 확인할 수 있다.\n","- 먼저 웹브라우저를 통해 크롤링하고자 하는 사이트에 접속해보자.\n","- 개발자 도구는 브라우저에서 일반적으로 `오른쪽 상단에 (...)를 클릭하여 도구 더보기 > 개발자 도구`를 클릭하면 보인다.\n","- 단축키는 F12 또는 Ctrl+Shift+I이다.(크롬 기준)"],"metadata":{"id":"q2XmnftBDmTx"}},{"cell_type":"markdown","source":["<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/web1.png\" width=\"500\",></div>"],"metadata":{"id":"Y1rdtiwYFonk"}},{"cell_type":"markdown","source":["- 개발자 도구로 들어가면 왼쪽에 창이 열리면서 웹페이지의 소스코드를 구조적으로 볼 수 있다.\n","- 소스코드 창 왼쪽 상단에 화살표 모양의 요소(element) 선택 버튼을 클릭한다.\n","- `요소 선택 버튼`은 현재 로딩된 웹페이지의 컨텐츠로 마우스를 가져가면 해당 요소의 상세 정보(태그 정보, CSS 정보)와 소스보기의 해당 요소 위치로 바로 이동시켜주는 기능을 제공한다.\n","- 마우스를 이동시킬 때마다 소스보기에서도 음영처리된 부분이 바뀌는 것을 볼 수 있을 것이다.\n","<div align=\"center\"><img src=\"https://haesunbyun.github.io/common/images/web2.png\" width=\"500\",></div>"],"metadata":{"id":"dhGXzWFWHcFy"}},{"cell_type":"markdown","source":["#### 태그로 찾기\n","- BeautifulSoup은 태그나 속성으로 찾을 수 있도록 하는 find()와 find_all() 메서드를 지원한다.\n","\n","```\n","soup.find('tag명'): 가장 처음에 있는 <tag명> 하나만 반환\n","soup.find_all('tag명'): <tag명>을 모두 찾아내어 리스트와 비슷한 형태로 반환.\n","```"],"metadata":{"id":"FRH0h76EI69Z"}},{"cell_type":"markdown","source":["- 먼저, find() 메서드를 사용해보자.\n","- 추출하려는 데이터가 \"L0444.000400 컴퓨팅 기초: 처음 만나는 컴퓨팅\"이라고 해보자.\n","- 추출하려는 데이터가 어떤 태그에 있는지 혹은 어떤 속성을 갖고 있는지 개발자 도구를 통해 확인한다.\n","- 확인을 했다면, 다시 코드로 와서 find()나 find_all()을 이용해 찾는다."],"metadata":{"id":"V_ll2pwxqGOY"}},{"cell_type":"code","source":["soup.find('p')"],"metadata":{"id":"TRVu98vlM07Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 검색된 `<p>`태그에서 문자열을 추출한다."],"metadata":{"id":"fc3qGpUH12xu"}},{"cell_type":"code","source":["soup.find('p').text"],"metadata":{"id":"okT12mZTqejd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 이번에는 find_all() 메서드로 모든 `<p>` 태그를 찾아보자."],"metadata":{"id":"BJvoV-q-q5vb"}},{"cell_type":"code","source":["ptagList = soup.find_all('p')\n","print(ptagList)"],"metadata":{"id":"cz_FKQk4M7hJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- find_all()의 결과는 'bs4.element.ResultSet'이다. 리스트는 아니지만 리스트처럼 보여지며, 리스트와 같이 접근이 가능하다."],"metadata":{"id":"HxsNpcIJ1qhv"}},{"cell_type":"code","source":["print(type(ptagList))\n","ptagList[0]"],"metadata":{"id":"D79an7k9qEJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","- 또한 문자열 추출도 가능하다."],"metadata":{"id":"nUDxiNtn1ti2"}},{"cell_type":"code","source":["ptagList[0].text"],"metadata":{"id":"VPfOFh7wrglF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 'bs4.element.ResultSet'은 반복가능한 데이터셋이다.\n","- 즉, 리스트처럼 반복문에서 활용할 수 있다."],"metadata":{"id":"vZo83kPar7mo"}},{"cell_type":"code","source":["for each in soup.find_all('p'):\n","  print(each.text)"],"metadata":{"id":"Nw-4rOw1p92B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for each in soup.find_all('a'):\n","  print(each.string)"],"metadata":{"id":"x3be5ohRIpCM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 속성으로 찾기\n","- find()나 find_all()함수에서 전달인자로 태그 안에 있는 속성명이나 속성값을 함께 지정하여 찾을 수도 있다.\n","- 조건을 여러개 지정하면 찾고자 하는 데이터에 더 근접하여 추출할 수 있다.\n","- 조건을 속성명만 줄 때에는 태그명을 생략할 수도 있다.\n","```\n","soup.find('tag명', 속성명='속성값')\n","soup.find_all(속성명='속성값')\n","```"],"metadata":{"id":"8MxGSWAy1Fei"}},{"cell_type":"markdown","source":["- 예를들어, 태그가 `<p>`이면서 class가 'caption'인 것을 모두 찾는다면 아래와 같이 쓸 수 있다.\n","- 이때 주의해야 할 것은 class라는 속성명은 반드시 class_로 써야 한다."],"metadata":{"id":"c8kVf0AqzmnU"}},{"cell_type":"code","source":["soup.find_all('p', class_='caption')"],"metadata":{"id":"MB_mJjbO1LoQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 속성명 class가 'toctree-l1'인 것을 모두 찾아서 내용만 출력한다."],"metadata":{"id":"sUQTnGrk2dDi"}},{"cell_type":"code","source":["a= soup.find_all(class_='toctree-l1')\n","for each in a:\n","  print(each.text)"],"metadata":{"id":"Op6GqQxf2cmn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 속성값 추출하기\n","- 어떤 경우에는 속성값을 추출해야 할 필요가 있기도 하다.  대표적인 예로 링크주소를 추출하고 싶을 때가 그렇다.\n","- 이럴 때에는 속성명을 활용하여 속성값을 추출하면 된다.\n","- 속성값을 추출할 때에는 태그 뒤 대괄호[ ] 안에  속성명을 문자열로 넣어주면 된다.\n","```\n","soup.find('p')['속성명']\n","```"],"metadata":{"id":"xUhcaTXP1JGX"}},{"cell_type":"markdown","source":["- 태그로 직접 접근해 속성값을 추출할 수 있다."],"metadata":{"id":"7ZatiW9sOA4y"}},{"cell_type":"code","source":["soup.a['href']"],"metadata":{"id":"gx4alct87S9B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- find() 메서드로 찾아 속성값을 추출할 수 있다."],"metadata":{"id":"jK3UP0w32Sdg"}},{"cell_type":"code","source":["soup.find('a')['href']"],"metadata":{"id":"bPgoe0lF5fhc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- find_all() 메서드로 찾아 속성값을 추출할 수 있다."],"metadata":{"id":"7ElyA2MI2UpC"}},{"cell_type":"code","source":["for each in soup.find_all('a'):\n","  print(each['href'])"],"metadata":{"id":"wTW2gF9T7aNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for each in soup.find_all('a'):\n","  print(f\"{each['href']} : {each.string}\")"],"metadata":{"id":"X-KX9F-NOeg_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 마무리\n","- 웹페이지를 만드는데 사용되는 언어중 하나가 바로 HTML이다.\n","- HTML은 태그와 내용으로 구성되어 있다.\n","- 웹페이지 크롤링은 urllib.request 모듈의 urlopen() 함수를 통해 할 수 있다\n","- BeautifulSoup() 함수는 HTML에서 데이터를 추출할 수 있도록 하는 함수로 HTML 구문 분석 기능을 갖고 있다.\n","- html에서 태그 찾기는\n","  - soup.find('tag명'): 첫 <tag명>을 찾아 반환\n","  - soup.find_all('tag명'): <tag명>을 모두 찾아 묶음으로 반환\n","  - 속성명 = '속성값'을 괄호안에 추가로 넣어서 찾을 수 있다.\n","- 태그에서 데이터 추출하기는\n","  - 속성값 추출하기: ['속성명'] 활용\n","  - tag의 Text 추출하기: get_text(), text, string 등으로 추출할 수 있다.\n","- 웹페이지의 구조를 파악하기 쉽도록 구조를 보여주는 도구가 바로 개발자 도구이다.\n","- 개발자 도구를 활용하여 추출하고자 하는 데이터의 태그명과 속성을 보다 쉽게 확인할 수 있다.\n"],"metadata":{"id":"qd79ookGJz8i"}}]}